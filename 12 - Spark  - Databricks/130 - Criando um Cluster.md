<<<<<<< HEAD
<<<<<<< HEAD
130. Criando um Cluster
Bom, uma vez que então o que você criou à sua conta no Databricks Community Edition, você vai fazer login, uma vez que você fez o login, você vai estar em uma página semelhante isso aqui. Se não tiver, basta você clicar aqui em cima que você vem para essa página inicial.

Bom, o que a gente precisa fazer? Antes de mais nada, provavelmente a gente vai precisar importar um conjunto de dados para poder utilizar o Spark nesse conjunto de dados, e a gente também vai precisar criar, importar os notebooks.
Mas antes disso a gente precisa criar um cluster, um serviço, um nó, um cluster de um único nó, de um único computador que vai ser capaz de fazer o processamento. Ou seja, ele vai ser capaz de utilizar o Spark, de rodar o Spark.
Então, isso é o primeiro passo.

Como a gente está numa versão gratuita, a gente tem algumas limitações para criar um cluster, mas a gente consegue criar um cluster suficiente aqui para a gente executar as atividades. A gente pode considerar que, mesmo havendo um único nó, a gente tem sim um cluster.

Então o que a gente vai fazer, você vai vir aqui nesta opção Compute e aqui a gente pode ver os clusters que a gente tem rodando, e a gente vai criar então um primeiro cluster. Eu vou clicar aqui em create Cluster e vou dar um nome aqui para o cluster. Eu vou dar aqui o nome de cientista de dados.
Só que a versão do Scala e do Spark pode deixar. Você pode deixar que, por exemplo, esta versão do Spark 3.1.2. Se você quiser utilizar uma mais recente, não tem problema. Vejam que aqui eu tenho gratuitamente 15 gigabytes de memória para o usuário gratuito.

Aí veja que ele está dizendo que como usuário da versão free o seu cluster, vai ser encerrado automaticamente depois de um período de inatividade de duas horas.

Aqui você tem a zona. Isso aqui você pode deixar como automático aqui algumas configurações do Spark que você pode precisar para inicializar a sua instância. A gente não vai mexer em nada aqui, então vamos clicar aqui em Create Cluster.

Então vejo aqui que para criar o cluster ele vai demorar alguns minutos.
Veja o que aqui ele está rodando aqui. Quer dizer que ele está criando o cluster, que pode demorar alguns minutos, não demora muito tempo, mas vai demorar sim, alguns instantes.
Depois de alguns minutos, você pode vir aqui que ficou verde e isso quer dizer que o cluster está pronto. O cluster cientista de dados está pronto e aqui existem várias guias você tem notebooks livres, logs de eventos, várias opções. Aqui também existem alguns botões ou você pode clonar, reiniciar, terminar o cluster.

Se você clicar aqui de novo em Computing, vai aparecer uma lista aqui dos nossos clusters, mas obviamente que a gente vai ter um só. Então a gente pode ver aqui que o nosso cluster está rodando, está pronto.
Isso quer dizer, então, que a gente pode começar a utilizar o Spark, porque a gente tem um cluster pronto. Então, a partir do próximo tutorial, a gente vai primeiramente fazer a importação de dados aqui no Databricks.
=======
130. Criando um Cluster
Bom, uma vez que então o que você criou à sua conta no Databricks Community Edition, você vai fazer login, uma vez que você fez o login, você vai estar em uma página semelhante isso aqui. Se não tiver, basta você clicar aqui em cima que você vem para essa página inicial.

Bom, o que a gente precisa fazer? Antes de mais nada, provavelmente a gente vai precisar importar um conjunto de dados para poder utilizar o Spark nesse conjunto de dados, e a gente também vai precisar criar, importar os notebooks.
Mas antes disso a gente precisa criar um cluster, um serviço, um nó, um cluster de um único nó, de um único computador que vai ser capaz de fazer o processamento. Ou seja, ele vai ser capaz de utilizar o Spark, de rodar o Spark.
Então, isso é o primeiro passo.

Como a gente está numa versão gratuita, a gente tem algumas limitações para criar um cluster, mas a gente consegue criar um cluster suficiente aqui para a gente executar as atividades. A gente pode considerar que, mesmo havendo um único nó, a gente tem sim um cluster.

Então o que a gente vai fazer, você vai vir aqui nesta opção Compute e aqui a gente pode ver os clusters que a gente tem rodando, e a gente vai criar então um primeiro cluster. Eu vou clicar aqui em create Cluster e vou dar um nome aqui para o cluster. Eu vou dar aqui o nome de cientista de dados.
Só que a versão do Scala e do Spark pode deixar. Você pode deixar que, por exemplo, esta versão do Spark 3.1.2. Se você quiser utilizar uma mais recente, não tem problema. Vejam que aqui eu tenho gratuitamente 15 gigabytes de memória para o usuário gratuito.

Aí veja que ele está dizendo que como usuário da versão free o seu cluster, vai ser encerrado automaticamente depois de um período de inatividade de duas horas.

Aqui você tem a zona. Isso aqui você pode deixar como automático aqui algumas configurações do Spark que você pode precisar para inicializar a sua instância. A gente não vai mexer em nada aqui, então vamos clicar aqui em Create Cluster.

Então vejo aqui que para criar o cluster ele vai demorar alguns minutos.
Veja o que aqui ele está rodando aqui. Quer dizer que ele está criando o cluster, que pode demorar alguns minutos, não demora muito tempo, mas vai demorar sim, alguns instantes.
Depois de alguns minutos, você pode vir aqui que ficou verde e isso quer dizer que o cluster está pronto. O cluster cientista de dados está pronto e aqui existem várias guias você tem notebooks livres, logs de eventos, várias opções. Aqui também existem alguns botões ou você pode clonar, reiniciar, terminar o cluster.

Se você clicar aqui de novo em Computing, vai aparecer uma lista aqui dos nossos clusters, mas obviamente que a gente vai ter um só. Então a gente pode ver aqui que o nosso cluster está rodando, está pronto.
Isso quer dizer, então, que a gente pode começar a utilizar o Spark, porque a gente tem um cluster pronto. Então, a partir do próximo tutorial, a gente vai primeiramente fazer a importação de dados aqui no Databricks.
>>>>>>> d9f734c334f4b5e550e5383e11b878ea9d28d555
=======
130. Criando um Cluster
Bom, uma vez que então o que você criou à sua conta no Databricks Community Edition, você vai fazer login, uma vez que você fez o login, você vai estar em uma página semelhante isso aqui. Se não tiver, basta você clicar aqui em cima que você vem para essa página inicial.

Bom, o que a gente precisa fazer? Antes de mais nada, provavelmente a gente vai precisar importar um conjunto de dados para poder utilizar o Spark nesse conjunto de dados, e a gente também vai precisar criar, importar os notebooks.
Mas antes disso a gente precisa criar um cluster, um serviço, um nó, um cluster de um único nó, de um único computador que vai ser capaz de fazer o processamento. Ou seja, ele vai ser capaz de utilizar o Spark, de rodar o Spark.
Então, isso é o primeiro passo.

Como a gente está numa versão gratuita, a gente tem algumas limitações para criar um cluster, mas a gente consegue criar um cluster suficiente aqui para a gente executar as atividades. A gente pode considerar que, mesmo havendo um único nó, a gente tem sim um cluster.

Então o que a gente vai fazer, você vai vir aqui nesta opção Compute e aqui a gente pode ver os clusters que a gente tem rodando, e a gente vai criar então um primeiro cluster. Eu vou clicar aqui em create Cluster e vou dar um nome aqui para o cluster. Eu vou dar aqui o nome de cientista de dados.
Só que a versão do Scala e do Spark pode deixar. Você pode deixar que, por exemplo, esta versão do Spark 3.1.2. Se você quiser utilizar uma mais recente, não tem problema. Vejam que aqui eu tenho gratuitamente 15 gigabytes de memória para o usuário gratuito.

Aí veja que ele está dizendo que como usuário da versão free o seu cluster, vai ser encerrado automaticamente depois de um período de inatividade de duas horas.

Aqui você tem a zona. Isso aqui você pode deixar como automático aqui algumas configurações do Spark que você pode precisar para inicializar a sua instância. A gente não vai mexer em nada aqui, então vamos clicar aqui em Create Cluster.

Então vejo aqui que para criar o cluster ele vai demorar alguns minutos.
Veja o que aqui ele está rodando aqui. Quer dizer que ele está criando o cluster, que pode demorar alguns minutos, não demora muito tempo, mas vai demorar sim, alguns instantes.
Depois de alguns minutos, você pode vir aqui que ficou verde e isso quer dizer que o cluster está pronto. O cluster cientista de dados está pronto e aqui existem várias guias você tem notebooks livres, logs de eventos, várias opções. Aqui também existem alguns botões ou você pode clonar, reiniciar, terminar o cluster.

Se você clicar aqui de novo em Computing, vai aparecer uma lista aqui dos nossos clusters, mas obviamente que a gente vai ter um só. Então a gente pode ver aqui que o nosso cluster está rodando, está pronto.
Isso quer dizer, então, que a gente pode começar a utilizar o Spark, porque a gente tem um cluster pronto. Então, a partir do próximo tutorial, a gente vai primeiramente fazer a importação de dados aqui no Databricks.
>>>>>>> d9f734c334f4b5e550e5383e11b878ea9d28d555

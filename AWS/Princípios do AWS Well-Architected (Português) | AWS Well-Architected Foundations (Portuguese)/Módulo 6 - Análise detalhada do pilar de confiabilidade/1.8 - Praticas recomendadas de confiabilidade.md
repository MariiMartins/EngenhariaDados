## 1.8 Práticas recomendadas de confiabilidade

Na nuvem, as práticas recomendadas podem ajudar a aumentar a confiabilidade.
Nesta seção, você saberá mais sobre essas práticas recomendadas.

## 1.9 Áreas de práticas recomendadas de sustentabilidade

As práticas recomendadas no pilar de confiabilidade estão organizadas em quatro áreas, sendo a primeira a de fundamentos. O escopo dos requisitos fundamentais vai além de uma única carga de trabalho ou projeto. Antes de projetar qualquer sistema, é necessário implementar requisitos fundamentais que influenciam a confiabilidade. Por exemplo, você deve ter largura de banda de rede suficiente para o seu data center. Em um ambiente on-premises, esses requisitos podem causar tempos de execução longos devido a dependências e, portanto, devem ser incorporados durante o planejamento inicial. No entanto, com a AWS, a maioria desses requisitos fundamentais já está incorporada ou pode ser abordada conforme necessário. A nuvem foi projetada para ser quase ilimitada, portanto, é responsabilidade da AWS satisfazer o requisito de capacidade suficiente computacional e de rede. Isso deixa você livre para alterar o tamanho e as alocações de recursos sob demanda.

A próxima prática recomendada é a arquitetura da carga de trabalho. Uma carga de trabalho confiável começa com decisões iniciais de design para o software e a infraestrutura. Suas escolhas de arquitetura afetarão o comportamento da carga de trabalho em todos os seis pilares do AWS Well-Architected. Para obter confiabilidade, há padrões específicos que você deve seguir.
Para a prática recomendada de gerenciamento de alterações, as alterações em sua carga de trabalho ou em seu ambiente devem ser previstas e acomodadas para uma operação confiável da carga de trabalho. As alterações incluem aquelas impostas à sua carga de trabalho, como picos de demanda. Elas também incluem alterações internas, como implantações de recursos e patches de segurança.

Por fim, no que se refere ao gerenciamento de falhas, as falhas de baixo nível dos componentes de hardware são algo com que se lida todos os dias em um data center on-premises. Na nuvem, entretanto, você deve estar protegido contra a maioria desses tipos de falhas. Por exemplo, os volumes do Amazon Elastic Block Store, ou Amazon EBS, são colocados em uma Zona de Disponibilidade específica, onde são replicados automaticamente para proteger você contra a falha de um único componente. Todos os volumes do EBS são projetados para uma disponibilidade de cinco noves. Os objetos do Amazon Simple Storage Service, ou Amazon S3, são armazenados em um mínimo de três Zonas de Disponibilidade, proporcionando onze noves de durabilidade para os objetos em um determinado ano. Independentemente do seu provedor de nuvem, há a possibilidade de falhas afetarem sua carga de trabalho. Portanto, você deve tomar medidas para implementar a resiliência se precisar que sua carga de trabalho seja confiável. Um pré-requisito para aplicar as práticas recomendadas discutidas aqui é garantir que as pessoas que estão projetando, implementando e operando suas cargas de trabalho sejam treinadas para os objetivos comerciais e as metas de confiabilidade para alcançá-los.

## 1.10 Fundamentos

Na área de práticas recomendadas de fundamentos, o escopo pode ir além de uma única carga de trabalho ou projeto. Ela precisa ser compreendida e implementada antes de arquitetar qualquer sistema. Caso contrário, você poderá enfrentar longos prazos de entrega e bloqueios ao longo do caminho. Cuide disso com antecedência para que você possa ficar livre para alterar o tamanho e a alocação dos recursos sob demanda. Nesta seção, você aprenderá a gerenciar cotas ou restrições de serviço e a planejar a topologia da rede.

## 1.11 Gerenciar cotas e restrições de serviço

Gerencie cotas e restrições de serviço. Para arquiteturas de carga de trabalho baseadas na nuvem, existem cotas de serviço (que também são chamadas de limites de serviço). Essas cotas existem para evitar o provisionamento acidental de mais recursos do que o necessário. Elas também ajudam a limitar as taxas de solicitação nas operações de API para proteger os serviços contra abusos. Há também restrições de recursos, por exemplo, a taxa de bits que você pode enviar até o cabo de fibra ótica ou a quantidade de armazenamento em um disco físico.

É uma boa ideia estar ciente das cotas padrão e das solicitações de aumento de cota para sua arquitetura de carga de trabalho. Além disso, você deve saber quais restrições de recursos, como disco ou rede, são potencialmente impactantes. Você também pode gerenciar cotas de serviço em contas e Regiões. Se você estiver usando várias contas ou Regiões AWS, certifique-se de solicitar as cotas apropriadas em todos os ambientes nos quais as cargas de trabalho de produção são executadas. As cotas de serviço são rastreadas por conta. Salvo indicação em contrário, cada cota é específica da Região AWS. Além dos ambientes de produção, gerencie também as cotas em todos os ambientes de não produção aplicáveis para que os testes e o desenvolvimento não sejam prejudicados.

Em seguida, acomode cotas de serviço fixas e restrições por meio da arquitetura.

Esteja ciente das cotas de serviço e dos recursos físicos imutáveis e arquitete para evitar que eles afetem a confiabilidade. Você também pode monitorar e gerenciar cotas. Avalie seu uso potencial e, em seguida, aumente suas cotas adequadamente com espaço para o crescimento planejado do uso. Automatize o gerenciamento de cotas implementando ferramentas para alertá-lo quando um limite se aproximar. Você pode automatizar as solicitações de aumento de cota usando Service Quotas APIs.

Por fim, garanta que haja uma lacuna suficiente entre as cotas atuais e o uso máximo para acomodar o failover. Quando um recurso é reprovado, ele ainda pode ser contabilizado nas cotas até que termine com sucesso. Verifique se suas cotas cobrem a sobreposição de todos os recursos com falha com as substituições antes que os recursos com falha terminem. Considere uma falha na Zona de Disponibilidade ao calcular essa lacuna.

## 1.12 Planejar a topologia da rede

Planeje sua topologia de rede. As cargas de trabalho geralmente existem em vários ambientes. Isso inclui vários ambientes de nuvem (acessíveis publicamente e privados) e, possivelmente, sua infraestrutura de data center existente. Os planos devem incluir considerações de rede, como conectividade intrassistema e intersistema, gerenciamento de endereços IP públicos, gerenciamento de endereços IP privados e resolução de nomes de domínio. Ao arquitetar sistemas que usam redes baseadas em endereços IP, é necessário planejar a topologia da rede e prever possíveis falhas. É importante acomodar o crescimento futuro e a integração com outros sistemas e suas redes.

Lembre-se de usar conectividade de rede altamente disponível para os endpoints públicos de sua carga de trabalho. Esses endpoints e o roteamento para eles devem estar altamente disponíveis. Para isso, use DNS altamente disponível, rede de entrega de conteúdo (CDN), gateway de API, balanceamento de carga ou proxies reversos. Forneça conectividade redundante entre redes privadas na nuvem e em ambientes on-premises. Use várias conexões do AWS Direct Connect ou túneis de rede privada virtual entre redes privadas implantadas separadamente. Você também pode usar vários locais do Direct Connect para ter alta disponibilidade. Se estiver usando várias Regiões AWS, garanta a redundância em pelo menos duas delas.

Você também pode garantir que a alocação da sub-rede IP leve em conta a expansão e a disponibilidade. Os intervalos de endereços IP do Amazon Virtual Private Cloud, ou Amazon VPC, devem ser grandes o suficiente para acomodar os requisitos de carga de trabalho. Isso inclui levar em conta a expansão futura e a alocação de endereços IP para sub-redes nas Zonas de Disponibilidade. Isso também inclui balanceadores de carga, instâncias EC2 e aplicações baseadas em contêineres.
Considere as topologias hub-and-spoke sobre a malha muitos-para-muitos se mais de dois espaços de endereço de rede, como VPCs e redes on-premises, estiverem conectados por meio de peering de VPC, Direct Connect ou VPN. O AWS Transit Gateway é um exemplo de um modelo hub-and-spoke.

Por fim, implemente intervalos de endereços IP privados não sobrepostos em todos os espaços de endereços privados aos quais eles estão conectados. Os intervalos de endereços IP de cada uma de suas VPCs não devem se sobrepor quando examinados ou conectados por meio de VPN. Da mesma forma, você deve evitar conflitos de endereços IP entre uma VPC e ambientes on-premises ou com outros provedores de nuvem que você usa. Você também deve ter uma maneira de alocar intervalos de endereços IP privados quando necessário.

## 1.13 Arquitetura de carga de trabalho

A arquitetura de carga de trabalho é a próxima área de práticas recomendadas de confiabilidade. Uma carga de trabalho confiável começa com decisões iniciais de design para o software e a infraestrutura. Suas escolhas de arquitetura afetarão o comportamento da carga de trabalho em todos os seis pilares do AWS Well-Architected. Para obter confiabilidade, há padrões específicos a serem incluídos. A seção a seguir explica as práticas recomendadas a serem usadas com esses padrões para garantir a confiabilidade. Você aprenderá a projetar sua arquitetura de serviço de carga de trabalho. Você também considerará as interações em um sistema distribuído para evitar, atenuar ou resistir a falhas.

<!--
CONTEÚDO ORIGINAL (EBOOKS)

## 1.2 - [Ebook] A IA não está eliminando Empregos. Está transformando Modelos de Negócios
A Inteligência Artificial (IA) tem o potencial de influenciar o mercado de trabalho, dependendo de sua utilização. Em certos casos, a IA pode automatizar tarefas previamente desempenhadas por seres humanos, o que pode resultar na substituição de trabalhadores por sistemas computacionais.

No entanto, a IA também gera oportunidades de emprego, como a necessidade de profissionais capazes de projetar, implementar e manter sistemas de IA. Além disso, a IA pode ser utilizada para aumentar a eficiência e produtividade em diversas atividades, permitindo que os trabalhadores se concentrem em tarefas mais complexas e criativas.

É importante ressaltar que a IA não é uma força autônoma que elimina empregos independentemente. Em vez disso, a IA consiste em um conjunto de ferramentas e tecnologias utilizadas por seres humanos para realizar tarefas de forma mais eficiente e eficaz.

O impacto da IA no emprego depende das decisões tomadas pelos seres humanos em relação à sua utilização, bem como da adaptação das políticas públicas e dos mercados de trabalho às mudanças causadas pela IA.

A IA pode ter um impacto significativo em vários modelos de negócios, mas isso não significa necessariamente a eliminação desses modelos. Ao contrário, a IA pode ser empregada para aprimorar e otimizar esses modelos de negócios, auxiliando as empresas a serem mais eficientes e a tomar melhores decisões.

Por exemplo, a IA pode automatizar tarefas repetitivas, liberando tempo para que os funcionários se dediquem a atividades de maior valor agregado. Além disso, ela pode analisar grandes volumes de dados e fornecer insights valiosos para a tomada de decisões empresariais.

No entanto, é importante lembrar que a IA também pode ter um impacto negativo em alguns modelos de negócios, como a substituição de trabalhadores humanos por robôs ou outras tecnologias de automação. Nesses casos, é fundamental que as empresas desenvolvam estratégias para garantir que os trabalhadores afetados sejam capacitados e realocados em novas posições, além de adotar medidas para mitigar quaisquer impactos negativos na economia e no mercado de trabalho.

## 2.5 - [Ebook] O futuro da Inteligência Artificial

Ao longo deste capítulo definimos Inteligência Artificial, conhecemos um pouco de sua história, áreas de pesquisa e campos relacionados, assim como a Sala Chinesa e o Teste de Turing. Estamos nitidamente num momento transitório, em que as tecnologias de IA estão evoluindo cada vez mais rápido e de forma irreversível. Mas e o futuro? O que mais avançado poderia ser feito com Inteligência Artificial? O objetivo deste texto é exatamente fazê-lo pensar no que está por vir. A verdade é que ainda estamos apenas no começo!

A ficção científica, por muitos anos, pregou um futuro em que os robôs seriam inteligentes e cyborgs seriam comuns. Filmes como "O Exterminador do Futuro", "Matrix", "Blade Runner", "Ex-Machina", "Her" e "Eu, Robô" são todos bons exemplos dessa visão.

Mas até a última década, a consideração do que isso poderia realmente significar no futuro era desnecessária porque era tudo ficção científica e não realidade científica. Agora, no entanto, a ciência não só conseguiu recuperar o atraso, como também introduziu aspectos práticos que permitem a aplicabilidade da IA em nossas vidas.

O que consideramos aqui são várias experiências diferentes ligando biologia e tecnologia em uma forma cibernética - essencialmente, em última análise, combinando seres humanos e máquinas em uma fusão relativamente permanente. Essa é uma linha de pesquisa que vem ganhando adeptos e evoluindo. O episódio 2 da terceira temporada da série "Black Mirror" na Netflix, retrata exatamente esse experimento. Assista se tiver oportunidade. O final é surpreendente. Outro exemplo é o excelente game de computador Titanfall 2, em que homem e máquina se ligam por um link neural, para formar um poderoso sistema de combate.

Quando normalmente pensamos em um robô, nós o consideramos simplesmente como uma máquina. Tendemos a pensar que ele pode ser operado remotamente por um ser humano, ou que pode ser controlado por um programa de computador simples.

Mas e se o robô tiver um cérebro biológico composto de células cerebrais, possivelmente até neurônios humanos? Os neurônios cultivados sob condições de laboratório em uma série de eletrodos não invasivos que fornecem uma alternativa atraente para realizar uma nova forma de controlador de robô. No futuro próximo, veremos robôs “pensantes” com cérebros não muito diferentes dos humanos. Você duvida?

Esse desenvolvimento levantará muitas questões sociais e éticas. Por exemplo, se o cérebro do robô tem aproximadamente o mesmo número de neurônios humanos que um cérebro humano típico, então poderia, ou deveria, ter direitos semelhantes aos de uma pessoa? Além disso, se esses robôs têm neurônios muito mais humanos do que em um cérebro humano típico - por exemplo, um milhão de vezes mais neurônios - eles, ao invés dos seres humanos, tomarão todas as decisões futuras?

Muitas interfaces computador / cérebro humano, são usadas para fins terapêuticos para superar problemas médicos ou neurológicos, com um exemplo, sendo os eletrodos de estimulação cerebral profunda, usados para aliviar os sintomas da doença de Parkinson. No entanto, mesmo aqui é possível considerar a utilização dessa tecnologia de forma que daria às pessoas habilidades que os seres humanos normalmente não possuem - em outras palavras, o aprimoramento humano. Em alguns casos, aqueles que sofreram amputações ou sofreram lesões na coluna devido a acidentes podem ser capazes de recuperar o controle através de seus sinais neurais ainda em funcionamento.

É claro que a conexão de um cérebro humano com uma rede de computadores através de um implante poderia, a longo prazo, abrir as vantagens distintas da inteligência da máquina, comunicação e habilidades de detecção para o indivíduo recebendo o implante. Atualmente, a obtenção de autorização para cada implantação requer aprovação ética da autoridade local que governa o hospital onde o procedimento é realizado. Mas, olhando para frente, é bem possível que as influências comerciais, juntamente com os desejos da sociedade para se comunicar de forma mais eficaz e perceber o mundo em uma forma mais rica, irá impulsionar o desejo do mercado.

Para alguns, as interfaces cérebro-computador são talvez um passo muito distante - particularmente se a abordagem significa interferência direta com o cérebro. Como resultado, a interface computador-cérebro mais estudada até o momento é a que envolve eletroencefalografia (EEG). Enquanto procedimentos de EEG possuem custo relativamente baixo, portátil e fácil de configurar, ainda é difícil ver a sua utilização futura de forma generalizada. Ele certamente tem um papel a desempenhar na avaliação externa de alguns aspectos do funcionamento do cérebro para fins médicos. No entanto, a ideia de pessoas dirigindo, enquanto usam um capacete de eletrodos, sem necessidade de um volante, não parece realista. Veículos completamente autônomos são muito mais prováveis.

Esses casos experimentais indicam como os seres humanos - e os animais, por assim dizer - podem se fundir com a tecnologia. Isso, por sua vez, gera um conjunto de considerações sociais e éticas, bem como questões técnicas. É por isso que é vital incluir um sentido de reflexão para que a experimentação adicional que agora testemunhamos seja guiada pelo feedback consciente

## 2.7 - [Ebook] Teste de Turing

As discussões contemporâneas sobre a natureza da mente são geralmente dominadas pelo que é conhecido como a concepção computacional, que identifica a mentalidade com a execução de programas: os seres humanos e as máquinas são supostos a operar de maneiras semelhantes. Talvez o mais importante representante desta posição seja Alan Turing, que introduziu o Turing Test (ou "TT") como um meio para determinar se as habilidades das máquinas eram comparáveis às dos seres humanos. A posição de Turing tem sido extremamente influente dentro da ciência cognitiva, que é dominada pelo modelo computacional da mente.

Embora o Teste de Turing tenha adquirido o status de conhecimento comum entre os estudantes de Inteligência Artificial e Ciência Cognitiva, seu caráter não é tão amplamente conhecido dentro da comunidade intelectual em geral. Turing adaptou um jogo, conhecido como o jogo de imitação (The Imitation Game), com a finalidade de provar a existência de inteligência ou mentalidade no caso de máquinas inanimadas. No jogo de imitação, um homem e uma mulher podem competir para induzir um competidor a adivinhar o que é feminino, baseado unicamente em respostas dadas a perguntas (permitindo que o macho, mas não a fêmea, minta).

O jogo precisava ser organizado de tal forma que as propriedades físicas dos participantes - suas formas, tamanhos e vozes, por exemplo - não tivessem influência. Então, se o competidor identificasse corretamente seu sexo, ele ou ela venceriam, mas de outra forma não. A concepção alternativa de Turing era adaptar o teste para colocar uma máquina inanimada contra um ser humano, onde a propriedade considerada não é mais a sexo dos participantes, mas sua inteligência ou mentalidade.

Para contornar o problema da falta de definição precisa para Inteligência Artificial, Alan Turing propôs em 1950, um teste capaz de determinar se uma máquina demonstra ou não inteligência (artificial), baseado no seguinte argumento:

“Não sabemos definir precisamente o que é inteligência e, consequentemente, não podemos de definir o que é inteligência artificial. Entretanto, embora não tenhamos uma definição de inteligência, podemos assumir que o ser humano é inteligente. Portanto, se uma máquina fosse capaz de se comportar de tal forma que não pudéssemos distingui-la de um ser humano, essa máquina estaria demonstrando algum tipo de inteligência que, nesse caso, só poderia ser inteligência artificial.”

Em 1950, Alan Turing publicou um artigo chamado “Computing Machine and Intelligence” (link do artigo na seção de link úteis). Neste artigo, Turing apresentou, pela primeira vez, o que hoje é conhecido por Teste de Turing, com o qual se pretendia descobrir se uma máquina podia ou não emular o pensamento humano. O Teste de Turing funciona da seguinte forma: um interrogador (humano) fará perguntas a duas entidades ocultas; uma delas é um humano e a outra é um computador. A comunicação entre o interrogador e as entidades é feita de modo indireto, pelo teclado, por exemplo. O interrogador tentará, através do “diálogo” realizado entre ele e as entidades, decidir qual dos dois é o humano. O computador será programado para se passar por humano e o humano responderá de forma a confirmar a sua condição. Se, no final do teste, o interrogador não conseguir distinguir quem é o humano, então conclui-se que o computador pode “pensar” segundo o Teste de Turing.

Em um de seus ensaios, Turing disse: “acredito que no fim do século o uso da palavra e a opinião, geralmente educada, terão se alterado tanto que alguém será capaz de falar de máquinas pensantes sem ser contraditado”. Porém já chegamos ao fim do século e entramos em outro e nenhuma máquina conseguiu passar, consistentemente, pelo Teste de Turing. Alguns computadores, devidamente programados, conseguiram passar por versões simplificadas do teste, contudo sempre esteve ausente o atributo mental do entendimento. Como Marvin Minsky, do MIT, disse: “o maior desafio é dar bom senso às máquinas, e bom senso é essencial para passar no Teste de Turing”. Russell e Norvig no clássico livro sobre Inteligência Artificial de 1995 (link na seção de bibliografia) observaram que programar um sistema de computador para passar no Teste de Turing é uma tarefa muito difícil. Tal sistema precisaria ter pelo menos as seguintes capacidades:

Processamento de linguagem natural para se comunicar com o usuário.
Representação de conhecimento para armazenar o que sabe ou aprende.
Raciocínio automatizado para usar o conhecimento armazenado com a finalidade de responder perguntas ou tirar novas conclusões.
Aprendizado de máquina para se adaptar a novas circunstâncias, detectar e extrapolar padrões, a fim de atualizar o seu conhecimento armazenado.
O Teste de Turing pode ser realizado de várias maneiras diferentes. Aqui o sucesso de uma máquina em induzir o concorrente a tratá-lo como humano seria tomado como prova de sua inteligência ou engenho.

A abordagem de Turing parece também enquadrar-se na tradição do “behaviorismo”, não apenas porque ele propôs um teste comportamental para a existência da mentalidade de máquina, mas também porque passar no Teste de Turing é suposto ser suficiente para justificar a existência da mentalidade. A máquina responder às perguntas de modo a induzir o competidor a adivinhar equivocadamente que a máquina é o humano, por exemplo, é visto como evidência suficientemente forte para justificar a conclusão de que a máquina possui mentalidade. Se ela passa pelo Teste de Turing, então ela possui uma mente, de acordo com esta concepção. Nesse sentido, a atribuição da mentalidade funciona como um modo abreviado de linguagem para a descrição do comportamento, onde atribuir essa propriedade não é cientificamente insignificante.

Mas o Teste de Turing sempre sofreu críticas, uma vez que existem muitas maneiras de responder e interpretar as perguntas.

O Teste de Turing foi adaptado para o cinema em 2015, no filme Ex Machina
<http://www.imdb.com/title/tt0470752>

## 2.8 - [Ebook] A sala chinesa

Pesquisadores da área de Inteligência Artificial dita “forte” acreditam que um dia haverá algum programa de computador tão complexo e sofisticado que será capaz de reproduzir qualquer tipo de ação desempenhada por um cérebro, inclusive raciocinar, tomar decisões inteligentes, ter sentimentos e tudo mais que hoje se pensa ser exclusivo de seres vivos, como os humanos. Note-se que eles falam de programas (“software”) que, em princípio, poderiam ser implantados em qualquer tipo de computador (“hardware”) suficientemente poderoso. Já o pessoal da IA dita “fraca” acha que esse computador apenas simularia o cérebro.

O filósofo norte-americano John Searle, da Universidade de Berkeley nos EUA, afirma que nenhum programa de computador, por mais complexo e avançado, será capaz de pensar. Para justificar sua objeção, Searle criou um experimento mental que ficou conhecido como a Sala Chinesa.

A Sala Chinesa (em inglês: Chinese Room) é um argumento hipotético criado por John Searle, em 1980, empregado por este em sua obra para refutar os teóricos da Inteligência Artificial forte. Baseia-se na presunção de que a sintaxe (gramática) não é garantia de existência da semântica (sentido).

Suponha que você, que não sabe absolutamente nada de chinês, está dentro de uma sala fechada onde existem caixas com coleções de símbolos chineses. Para você, que só entende português, esses símbolos não têm qualquer significado. Mas, existe na sala um enorme manual de instruções escrito em português que ensina como manipular esses símbolos. Outra pessoa, conhecedora da língua chinesa, está fora da sala e organiza perguntas ou frases coerentes em chinês, sobre qualquer assunto, juntando símbolos em pacotes que são passados para você através de uma abertura. Seu trabalho será usar o manual de instruções para formar uma nova coleção de símbolos que produza uma resposta coerente (em chinês) às questões que recebeu pela abertura. Considerando que os símbolos e o manual sejam bem completos, a pessoa do lado de fora vai achar que está se comunicando com alguém que sabe chinês. Sendo que você, na verdade, não sabe absolutamente nada dessa língua.

A Sala Chinesa pode ser considerada como um “computador” que aparenta saber chinês sem saber. Da mesma forma, diz Searle, um computador que passa pelo famoso Teste de Turing aparenta pensar, mas não pensa, pois não dispõe dos processos mentais inerentes ao pensamento. Abaixo, a descrição do experimento original criado por John Searle (traduzido para o português).

   Acesse também este vídeo com o experimento sendo realizado por um repórter da BBC, na série “The Hunt for AI”: <https://www.youtube.com/watch?v=D0MD4sRHj1M>

John Searle descreve uma sala hipotética com uma pessoa, o operador. Vários cestos com papéis onde estão desenhados ideogramas chineses estão na sala, assim como um livro de regras, escrito em inglês, de como combinar os ideogramas chineses. A pessoa recebe por um guichê de entrada uma sequência de ideogramas; utilizando o livro de regras, combina esses ideogramas de entrada e alguns que estão nos cestos, compondo uma nova sequência, que é então passada para fora da sala através de um guichê de saída. O operador não sabe o que está fazendo; na verdade, ele está respondendo perguntas em chinês. Searle argumenta que há uma distinção essencial entre esse operador e uma pessoa que leia e entenda chinês e responda perguntas sem utilizar um livro de regras. O primeiro está apenas seguindo regras sintáticas, mas o último está associando semântica ao que está fazendo. Searle afirma que a segunda pessoa está fazendo mais do que a primeira, porque entende o que cada pergunta e resposta significa. Ele diz, corretamente, que computadores são simplesmente máquinas sintáticas, combinando símbolos seguindo regras predeterminadas. Assim sendo, um computador pode substituir o operador daquela sala. Mas seres humanos fazem mais, eles associam significado, semântica, ao que eles observam e pensam. Como ele diz: "Há algo mais em ter uma mente do que executar processos formais ou sintáticos." Consequentemente, computadores nunca poderão pensar, porque pensar envolve semântica. Programas não são suficientes para atribuir mentes a computadores. Infelizmente, ele toma significado e semântica de uma forma ingênua, e não elabora sobre esses conceitos. Searle define a seguinte premissa: ele diz que "cérebros geram mentes", quer dizer, mentes são meros resultados, consequências de nossos cérebros físicos. Uma vez que abandonamos esse ponto de vista, é possível elaborar mais sobre o que pode ser entendimento, significado e semântica. O ponto importante agora é que essa premissa não invalida o argumento de sua sala chinesa. De acordo com esse argumento, computadores nunca poderão pensar.

Inteligência Artificial, portanto, é a capacidade do computador de reconhecer padrões e objetos, em velocidade cada vez maior e com isso “simular” o cérebro humano, usando diversas técnicas computacionais, matemática e estatística.

Alguns proponentes da IA “forte” argumentam que a pessoa dentro da sala pode até não saber chinês, mas, a sala toda (a pessoa, as caixas de símbolos e o manual de instruções) sabe. Isto é, o “sistema” completo sabe chinês, como o computador que passa pelo Teste de Turing pode também ser considerado como “pensante”.

Searle não concorda com essa conclusão e argumenta que a sala é até desnecessária. A pessoa que está nela poderia, em princípio, ser dotada de uma memória excepcional e decorar tudo, símbolos e manual. A troca de símbolos poderia acontecer fora da sala, os dois humanos frente a frente. O “sistema”, ou o homem que decorou tudo, se apresentaria como se fosse um surdo-mudo, comunicando-se em chinês por esses conjuntos de símbolos. Mesmo assim, segundo Searle, não seria correto dizer que a pessoa saberia chinês. “Conversar” em chinês não equivale a “entender” chinês. Essa pessoa, ou um programa de computador em seu lugar, estaria usando apenas a “sintaxe” da língua chinesa, mas não teria acesso à sua “semântica”.

Um computador usual funciona em série, manipulando bits de forma sequencial. Mas, já existem computadores com processamento paralelo e uma arquitetura que tenta reproduzir a estrutura de um cérebro (as GPUs – Unidades de Processamento Gráfico – que estudaremos no curso de número 3 da Formação IA), com neurônios e sinapses matemáticas a ponto de serem modificadas à medida que a máquina vai recebendo novas informações. Em outras palavras, esse tipo de computador que usa uma rede neural artificial é capaz de “aprender” enquanto manipula os dados que recebe. Se um computador desse tipo for usado em uma Sala Chinesa de Searle, sua troca de informação com o humano chinês seria cada vez mais elaborada e perfeita. Nesse caso, poderíamos dizer que essa máquina acabaria “entendendo” chinês?

Searle protesta dizendo que esse exemplo contradiz os defensores da IA “forte”, pois depende não apenas do programa (o “software”). Assim mesmo, segundo ele, essa máquina nunca entenderia o chinês, apenas simularia esse entendimento. Um computador e seu programa, por mais sofisticados, apenas processam informações – e processamento de informação não equivale a pensar.

Na verdade, diz Searle, o pensamento consciente deriva, necessariamente, de processos físico-químicos que não são reproduzidos em nenhum computador. A mente, segundo ele, não pode ser dissociada do cérebro. Aliás, não apenas do cérebro, mas de todo o organismo que interage com o cérebro trocando informações enquanto troca moléculas biológicas. A ideia, usada por autores de ficção científica, de que seria possível “exportar” uma mente de um cérebro para uma máquina externa, é inteiramente equivocada, segundo o filósofo americano.

O matemático inglês Roger Penrose concorda com Searle e também acha que uma mente não pode ser reproduzida por um algoritmo. No entanto, ele acha que os processos mentais dependem de processos quânticos, como a superposição de estados. Esses processos, ausentes de sistemas ou máquinas clássicas, seriam essenciais para o funcionamento de uma mente consciente. Essa é outra vertente muito interessante da controvérsia sobre máquinas “pensantes” que vale a pena acompanhar.

## 3.1 - [Ebook] Aprendizagem Humana x Aprendizagem de Máquina
Aprendizagem Humana x Aprendizagem de Máquina

O Processo de Aprendizagem Humana é o mecanismo pelo qual o conhecimento é adquirido, compreendido e incorporado. Ele pode ser descrito como um conjunto de transformações mentais que ocorrem em resposta a estímulos ou experiências. Em geral, o processo de aprendizagem envolve três fases:

    Aquisição: durante esta fase, o indivíduo é exposto a nova informação ou estímulo e essa informação é processada e armazenada na memória.

    Retenção: essa fase se concentra na manutenção da informação adquirida. Isso inclui a capacidade de acessar a informação quando necessário e a capacidade de evocá-la para uso futuro.

    Recuperação: essa fase se concentra na utilização da informação adquirida. Isso inclui a capacidade de aplicar o conhecimento adquirido em novas situações ou problemas, e a capacidade de adaptar o conhecimento adquirido para se adequar a novos contextos.

Existem vários modelos e teorias que tentam explicar como o processo de aprendizagem ocorre, incluindo teorias cognitivas, neurobiológicas e comportamentais. Além disso, existem diferentes tipos de aprendizagem, como aprendizagem declarativa, não-declarativa, por condicionamento, por observação, entre outros.

Já o Processo de Aprendizagem em Inteligência Artificial (IA) se refere ao processo pelo qual os algoritmos de IA são treinados para realizar tarefas específicas. Em geral, os algoritmos de IA são treinados com grandes conjuntos de dados, conhecidos como dados de treinamento, e os parâmetros do algoritmo são ajustados de maneira que o algoritmo possa realizar a tarefa desejada com maior precisão e eficiência.

Existem vários tipos de aprendizagem de IA, incluindo aprendizado supervisionado, não-supervisionado e por reforço. Cada tipo de aprendizado é usado para resolver problemas diferentes e tem suas próprias vantagens e desvantagens.

Além deles, existem outras formas de aprendizado, como aprendizado por transferência e aprendizado profundo, que são uma combinação de diferentes tipos de aprendizado e têm aplicações específicas.

Em geral, o processo de aprendizagem de IA inclui as seguintes etapas:

    - Coleta e preparação dos dados.
    - Escolha do algoritmo e configuração dos parâmetros.
    - Treinamento do modelo com os dados de treinamento.
    - Avaliação do modelo com dados de teste.
    - Ajuste do modelo e retreinamento, se necessário.
    - Uso do modelo para fazer previsões sobre novos dados.

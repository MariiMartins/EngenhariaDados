15. Projetos 

A gente vai falar então um pouco sobre projetos de big data. Quando a gente desenvolve algum serviço, algum produto de big data, esse desenvolvido através de um projeto, pode ter diferentes, muitos tipos de projetos de big data. Então aqui a gente está vendo alguns.

Então, por exemplo, projetos de ETL ou mesmo projetos de ELT 
Se for um projeto de big data, ele vai ser um projeto de ELT. Então, esse tipo de projeto são projetos que têm que fazer gestão de grandes volumes de dados. Eventualmente, tem que ter processos de transformação de dados.

Depois, tem projetos que são de processamento de dados, como, por exemplo, gerar arquivos de conformidade. 
Sistemas de integração que você tem que gerar dados ou prover serviços para entregar dados através, por exemplo, de uma API ou gerar mesmo arquivos texto para algum processo de integração são projetos de integração de dados.

E também projetos que desenvolvem aplicações e softwares, dashboard. São tipos de projetos que têm usuários finais. Um aplicativo para celular que tem alguma funcionalidade relacionada a dados a análise preditivas. A Inteligência artificial, aplicações web e muitas aplicações self-service. Indicadores, enfim, são diversos tipos de aplicação, que são as chamadas aplicações orientadas a dados.

Os projetos de Big Data são extremamente semelhantes a projetos de software e, claro, têm suas particularidades, mas têm muitas coisas em comum, e deve ser considerado que há obviamente testes e ferramentas de automação de testes. Tem, por exemplo, alguns citados Selenium e etc.

Uma outra ferramenta interessante que pode ser utilizada em projetos de Big Data, aqui especificamente em ambientes distribuídos, que é Chaos Monkey, uma ferramenta criada pelo Netflix que introduz falhas no sistema no ambiente do cluster para testar a resiliência, para testar tolerância, a falha da solução. 

Depois aspectos de build e deployment.Se você quanto mais você tem o Build e o Deploy automatizado, mais você minimiza riscos. E aqui a gente tem algumas ferramentas que são utilizadas para automação ferramentas de gestão de configuração, como o Puppet ou Chef, e o container como o Docker, uma ferramenta de container como o Docker.

Uma outra questão importantíssima em soluções de big data é desenvolver o projeto de modo modular e desacoplado. O que quer dizer isso que você desenvolve, Você divide o seu projeto em módulos e você desenvolve isso de forma independente. Então, por exemplo, você desenvolve o seu banco de dados de uma forma independente o processo de ETL de extração, transformação e dados independente.

O módulo de auditoria você cria como uma ferramenta independente. A ferramenta de monitoramento também é o front-end da aplicação também. Então, se você desenvolve a sua solução de forma modular, você tem um monte de vantagens. Ela fica de manutenção mais fácil. Ela fica com a questão de deploy configuração mais fácil, você tem muito mais vantagem criando o projeto de forma desacoplado. 
E, por fim, definir métricas mínimas de performance que a aplicação ela deve ter quando ele estiver pronto.Então, por exemplo, tempo de resposta, taxa de transferência (daí que a quantidade de dados transferidos de um lugar para outro), capacidade de carga da aplicação. São apenas alguns exemplos de algumas métricas que é importante que sejam definidas no projeto.

Essas métricas são também importantes para que se possa avaliar na entrega do projeto se ele atingiu os objetivos com o qual ele foi programado, com o qual o projeto foi planejado. Tempo de resposta, taxa de transferência e capacidade de carga são exemplos, mas cada projeto deve ter suas próprias métricas mínimas de performance.
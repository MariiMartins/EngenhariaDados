18. Riscos Parte I

A gestão de risco refere se a processos que ocorrem durante todo o projeto. Por uma razão óbvia os riscos estarão sempre presentes, mesmo que a sua probabilidade de impacto varie ao longo do projeto. Porém, diversas técnicas podem ser executadas já no início do projeto, ou seja, na sua fase embrionária. De forma a minimizar a ocorrência de risco. Às vezes você não sabe a qualidade dos dados, a latência do processo, a taxa de crescimento, entre tantos outros fatores que influenciam o projeto. 

Provas de conceito, protótipos e projetos pilotos podem esclarecer várias questões sobre o projeto e minimizar de forma muito ampla os riscos.

•	Prova de conceito é o desenvolvimento de um pequeno projeto como uma pequena fração do que está destinado ao projeto e por isso é desenvolvido em um curto espaço de tempo, com poucos recursos e com um escopo bem restrito, com o objetivo de validar um ou mais dos conceitos e, consequentemente, se minimizam riscos.

•	Já um protótipo diferente da prova de conceito vai tentar simular todo o projeto ou pelo menos grande parte dele pode ser feito com um sistema não oficial que ainda poderá ser desenvolvido. Um protótipo pode ser feito em vários níveis de intensidade e nem sempre significa implementar código. Por exemplo, para um projeto cuja entrega final seja um paineis de visualização de dados. Um protótipo pode ser esses painéis desenhados em uma ferramenta, como por exemplo, um balsamic ou visual, ou uma ferramenta que você possa desenhar interfaces para que o usuário possam analisar se é aquilo de fato que eles esperam receber ao final do projeto. Em outros casos, pode ser necessário desenvolver de fato os extratores e produzir os painéis de forma não estruturada e usando, por exemplo, uma base de dados de desenvolvimento. Depois de aprovados, os protótipos, em muitos casos pode até ser descartados para dar início ao desenvolvimento oficial do produto.

•	Já um piloto. A gente tem o sistema oficial a ser implantado, que é utilizado e testado, além de ser um processo de minimização de riscos certas organizações exigem que o sistema sejam amplamente testados e validados em um ambiente paralelo em que não exista ligação lógica ou física com a sua infraestrutura oficial para validar o produto em termos de segurança, desempenho e conformidade com as políticas da organização.

Nem sempre é necessário a implementação de provas de conceitos, protótipos ou pilotos.
Esta é uma decisão que é tomada pela equipe do projeto. É importante lembrar que tais processos requerem orçamento e tempo e esses processos podem nos dar informações vitais para decidir se o projeto deve continuar ou não isso porque se pode concluir que o projeto vai custar, por exemplo, mais caro do que o orçamento disponível para o mesmo, pode se chegar à conclusão que, para o projeto prosseguir, será preciso adquirir uma ferramenta de extração com custo na casa dos seis dígitos ou mesmo que o projeto simplesmente é inviável. Você pode descobrir antes de começar que o projeto é inviável. Por exemplo, certos dados que são vitais para o projeto simplesmente não se conseguem instalar esses dados por estar em um formato proprietário, por estarem criptografados.

Uma última questão aqui nesse slide é que um POC, uma POC pode criar um MVP, ou seja, um mínimo viable do produto, que é um produto mínimo com as características mínimas para se tornar um produto de mercado.
Outra questão com relação a avaliação de risco são as medidas. As medidas são um elemento problemático em muitos projetos, medidas que são cálculos se a gente fosse definir isso de forma simplificada, a gente define medidas como cálculos que têm que ser feitos lá durante o processo de geração de informação e conhecimento. As medidas mais comuns normalmente simplesmente somam a ocorrência de um fato em um determinado período, de acordo com o nível de granularidade. Esse é o nível mais simples de medida.

Então, por exemplo, o total de vendas por um produto. Isso é uma forma de medida. Porém, muitas vezes, a equação resultante da medida é bastante complexa.
Outro grande problema com medidas é quando sua fórmula de cálculo não é conhecida pela própria área de negócio da empresa. É bem comum também ocorrer de não haver um consenso entre os colaboradores, entre a área de negócio da empresa, de um mesmo departamento sobre como determinada medida deve ser calculada.

Não é raro acontecer, por exemplo, na mudança do responsável por um determinado setor de uma determinada área da empresa, Eles, concluem que os cálculos das medidas estavam sendo feitos de forma incorreta, ou seja, todo processo de mapeamento de dados, de extração, de criação de fórmulas de deixemos, ou seja, tudo tem que ser refeito para o que se concluiu que alguma medida estava errado.

Com relação a modelos com projetos de Big Data e Data Science, às vezes depende da criação de um modelo para quem não é familiarizado com esse conceito de modelo. Aqui vai uma breve explanação e uma breve explicação.

Análises preditivas, por exemplo, usam dados do passado para prever o futuro.
Para fazer a previsão, esses dados históricos são submetidos a um algoritmo que processa esses dados e produz o modelo. Então, o modelo nada mais é do que uma referência para prever eventos futuros. Uma vez construído o modelo o sistema preditivo não precisa mais dos dados históricos nem do algoritmo. Tudo o que ele vai precisar é das informações que precisam ser previstas, que são submetidas ao modelo que tem como saída a previsão.

A criação de modelos apresenta alguns problemas relacionados a riscos, algumas questões relacionadas a riscos.
O primeiro é que os envolvidos no projeto podem esperar taxas de acertos irrealistas, por exemplo, 75% de acerto em um modelo preditivo e uma taxa comum e em alguns casos, considerada uma taxa de sucesso. Para outros projetos, pode não ser satisfatórios ou satisfatórios depende muito do negócio. 
Então, é preciso, já no início do projeto, deixar claro com os envolvidos quais são as expectativas de sucesso do projeto com relação à precisão do modelo. Outro problema que simplesmente pode não ser possível criar o modelo com as taxas de acerto mínimas. São dois motivos principais que inviabilizam. 
O primeiro, e mais comum, é que não existem atributos suficientes nos sistemas de origem para produzir o modelo ou se os atributos existem, eles não estão preenchidos. 
O que eu quero dizer com isso? Por exemplo, se o objetivo do projeto é criar um modelo preditivo para reduzir evasão escolar, é preciso um conjunto mínimo de atributos. Por exemplo, a idade do aluno, a profissão, o local onde ele mora, se ele é casado, o estado civil, o sexo e às vezes você não encontra esses atributos.

O segundo impeditivo mais provável para que você não consiga ter um bom modelo é quanto à qualidade dos dados. Quer dizer, os dados existem, mas a qualidade torna a criação do modelo inviável, isso pode colocar em risco qualquer tipo de projeto de big data obviamente. O maior problema com relação a modelos ineficientes é que a equipe do projeto pode vir a descobrir isso tarde demais, quando já se passaram meses de projeto. Já se gastou boa parte do orçamento e as expectativas dos envolvidos estão ainda maiores. 
Então, para minimizar esse tipo de risco, um piloto como a gente viu há pouco, uma análise de viabilidade técnica prévia pode, em pouco tempo e com baixo custo, mostrar se o projeto é inviável do ponto de vista do modelo.

O piloto poderia consistir, por exemplo, em extrair manualmente dados dos atributos transacionais e submetê los a um algoritmo para avaliar a precisão.  Algoritmos de seleção de atributos também podem ser utilizados para identificar quais atributos seriam os mais relevantes.

Expectativas de tempo não realistas.
Partes interessadas, sem muita experiência ou com nenhuma experiência em projetos de big data, pode imaginar que em algumas semanas eles vão ter todo tipo de informação, por exemplo, financeira à sua disposição. Grandes projetos de Big Data pode levar muitos meses ou até anos. Construir, por exemplo, DataLake corporativo pode facilmente envolver projetos em horas na casa de cinco dígitos, quando o projeto depende ainda de fornecedores os prazos podem ser ainda mais dilatados. Então, é importante que a equipe do projeto, desde o início, gerencia as expectativas com relação a tempo. A preposição de entregas parciais e constantes, quando possível como se propõe as metodologias ágeis, pode ser uma forma interessante de minimizar falsas expectativas e desconfiança, por exemplo, das partes interessadas.

# Com relação à segurança e privacidade.
Então, a gente falou anteriormente sobre alguns aspectos de segurança de dados. A gente viu que a segurança deve ser vista sob diversos aspectos. Tem autenticação, autorização, Data at Rest, Data at Wire,  comunicação entre os nós, enfim.Então, a segurança deve estar amplamente inserida na gestão de riscos do projeto, mesmo que se trate de dados com uma grande flexibilidade nesse quesito. Dados de acesso público e universal, por exemplo.

Mesmo assim, existem várias ameaças que podem tornar, por exemplo, o sistema indisponível. Podem corromper os dados, pode adulterar os dados ou simplesmente vandalizar o ambiente. Então, só lembrando, mais uma vez, que os aspectos de segurança não são uma responsabilidade exclusiva do engenheiro de dados, mas ele tem a  responsabilidade compartilhada.

# Requisitos de cultura e idioma.
Eles estão, claro, são suportados pela ferramenta, o que quer dizer requisitos de cultura, idioma. Se você está criando um projeto global que vai demonstrar dados, por exemplo, dashboards e interfaces de forma global para diversos países, a sua ferramenta vai ter que suportar questões de tradução, de interface, exibição de moedas e data de acordo com a cultura, alinhamento de texto, então, esta é outra questão a ser considerada.

No projeto a questão de testes.
Eu costumo dizer que os projetos de big data têm muita semelhança, têm muito em comum com projetos de desenvolvimento de software, então, são projetos que têm que ser testados. Eles têm que ter planos de teste. Eles têm que ter caso de teste e eles devem ser testados através de ferramentas de automação de testes, que traz um grande ganho de produtividade, de eficiência na execução dos testes.

Sua empresa vai investir um valor significativo na construção de um cluster fabuloso. Porém, devido a um bug em um produto de streaming de dados, a solução para então simplesmente a solução para então, veja que, neste caso, um bug no sistema para a solução não adianta alta disponibilidade.Não adianta replicação, não adianta particionamento redundância, pois o problema está no software que vai estar espalhado em todos os nós. Então o cluster inteiro vai para. Então o que a gente quer falar? Que a gente quer falar da maturidade ou da imaturidade de sistemas? 
O Gartner propõe aqui Hype Cycle que ele trata desse aspecto de maturidade, de uma solução. E aqui, as diversas, as principais fases que um software,  um software que classicamente passou por essas etapas aqui, o próprio Hadoop.
Então, primeiro ele teve lá a fase, que é o trigger, e que o produto ele foi criado e teve um período de incubação. 
Logo depois, ele teve um pico de expectativas infladas de altas expectativas. Com o Hadoop, isso foi exponencial. 
Então teve promessa de um produto maravilhoso, estável, altamente funcional. Outra característica interessante é que ninguém podia, por exemplo, duvidar das funcionalidades do produto ou achar que o produto ele não era tão maravilhoso assim.

Então ele era tão, altamente idolatrado, entre aspas, que simplesmente ninguém poderia discordar. E era quase como um fã de um, de um exemplo de um ator de cinema. Uma analogia interessante, logo depois, tem a fase da desilusão. Os usuários, eles começam a usar e começam a encontrar problemas, problemas de segurança, de integração e disponibilidade. Uma questão interessante quando se desenvolve novos produtos é que aspectos secundários eles deixam para ser desenvolvidos depois ou são desenvolvidos inicialmente, mas de forma bem arcaica, de forma bem simples. Então, por exemplo, um sistema de processamento de dados, o que é uma funcionalidade secundária?  Por exemplo, segurança, integração, a disponibilidade.

Primeiro se preocupa em desenvolver a funcionalidade core dele. Tanto é que o Hadoop na primeira versão dele lá, ele não tinha praticamente nenhuma funcionalidade ou características relacionada à segurança. Depois o software começa a se estabilizar e então ele começa a ser usado em maior volume e se estabilizar, e por fim, ele entra no platô da produtividade. O produto se consolida. Depois, ele começa a ser utilizado amplamente pelo mercado.

Já se consegue você já ver amplamente pessoas demonstrando os pontos fracos, os pontos fortes no que ele é bom e no que é ruim, porque ele não serve, já existem produtos alternativos e, obviamente, depois do produto ele vai em algum momento entrar em uma fase de declínio, que o produto não vai mais ter as características ou as cartilhas funcionalidades.Para a qual ele inicialmente era proposto. Ele não vai mais resolver os problemas da forma que ele é proposto, ou existirão outras soluções que trarão uma solução melhor para o problema. 
Então, só para a gente deixar claro que uma questão importantíssima com relação à mitigação de riscos em projetos de Big Data é sempre observar a maturidade da solução que se quer utilizar.